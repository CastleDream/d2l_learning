{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. softmax回归的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过深度学习框架的高级API能够使实现softmax回归变得更容易"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import d2l_torch as d2l\n",
    "\n",
    "batch_size=256\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0089,  0.0113, -0.0199,  0.0070, -0.0123],\n",
      "        [-0.0041,  0.0079,  0.0057,  0.0080,  0.0029],\n",
      "        [ 0.0103,  0.0111,  0.0264, -0.0135,  0.0078],\n",
      "        [ 0.0047,  0.0201, -0.0006, -0.0007,  0.0184],\n",
      "        [ 0.0172,  0.0051,  0.0040, -0.0029,  0.0116]],\n",
      "       grad_fn=<SliceBackward>) torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参见额外扩展中->代码中的flatten验证部分说明\n",
    "net=nn.Sequential(nn.Flatten(),nn.Linear(784,10))\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0.01)\n",
    "        # 使用正态分布对某个层进行初始化，mean默认为0，std默认为1\n",
    "        print(m.weight[:5,:5],m.weight.shape)\n",
    "net.apply(init_weights)\n",
    "# 对调用者的每个子模块应用函数，最典型的使用就是模型初始化的时候"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，`Linear`网络的输入输出是784\\*10，刚好和`Linear`的weight形状10\\*784是对称的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考 额外扩展 -> pytorch中的CrossEntropyLoss\n",
    "# 在交叉熵损失函数中传递未归一化的预测，并同时计算softmax及其对数。\n",
    "loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**总结**\n",
    "\n",
    "简洁实现和从0实现之间的对应关系\n",
    "\n",
    "|简洁实现|从0实现|作用|\n",
    "|---|---|---|\n",
    "|nn.Flatten() |reshape |将输入数据变成二维的|\n",
    "|init_weights()| 对W和b赋值|初始化|\n",
    "|CrossEntropyLoss|-torch.log(softmax())|加入-log的softmax作为损失函数|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 额外扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码中的flatten()验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_iter:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax回归的 输出层 是一个全连接层。\n",
    "\n",
    "+ 由于pytorch不会隐式的帮助我们调整输入的形状\n",
    "+ 因此，定义展平层(flatten)在线性层前调整网络输入的形状\n",
    "+ flatten的作用是把输入的任意维度的tensor变成一个2d的tensor，其中输入tensor的第0维保留，剩下的维度全部展成一个向量。\n",
    "    + 函数说明中：Args:\n",
    "        + start_dim: first dim to flatten (default = 1).\n",
    "        + end_dim: last dim to flatten (default = -1).\n",
    "    + 这个flatten就对应softmax从头实现里的reshape函数\n",
    "+ train_iter中每个batch的size如上，其实是256个 通道数为1，大小为28\\*28的图像\n",
    "+ 但是由于Linear网络层接收的输入输出只能是一维的，所以使用Flatten压扁，变成256\\*784，如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 784])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_iter:\n",
    "    m = nn.Sequential(nn.Flatten())\n",
    "    output = m(X)\n",
    "    print(output.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flatten()和conv2d()函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于flatten()，可以看下面这个例子\n",
    "+ 输入是32个1通道 5\\*5的图像\n",
    "+ 使用的2d卷积，\n",
    "    + `in_channel`=1,\n",
    "    + `out_channels`=32\n",
    "    + `kernel_size`=5\\*5\n",
    "    + `stride` = 1,\n",
    "    + `padding`= 1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 288])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(32, 1, 5, 5)\n",
    "m = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 5, 1, 1),\n",
    "    nn.Flatten()\n",
    ")\n",
    "output = m(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "288=32\\*3\\*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(32, 1, 5, 5)\n",
    "m = nn.Sequential(nn.Conv2d(1, 32, 5, 1, 1))\n",
    "output = m(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch中的CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从0实现中，是cross_entropy调用了softmax。而pytorch对于交叉熵损失函数的实现是：\n",
    "[torch.nn.CrossEntropyLoss.html](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
